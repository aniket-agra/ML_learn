{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My First TensorFlow Code\n",
    "\n",
    "We will try to build a customisable, fully connected Neural Network. We'll need to use tf_utils to load dataset. We'll check later how to read h5 datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Aniket/anaconda3/envs/aniket1/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/Aniket/anaconda3/envs/aniket1/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/Aniket/anaconda3/envs/aniket1/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/Aniket/anaconda3/envs/aniket1/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/Aniket/anaconda3/envs/aniket1/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/Aniket/anaconda3/envs/aniket1/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/Aniket/anaconda3/envs/aniket1/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/Aniket/anaconda3/envs/aniket1/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/Aniket/anaconda3/envs/aniket1/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/Aniket/anaconda3/envs/aniket1/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/Aniket/anaconda3/envs/aniket1/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/Aniket/anaconda3/envs/aniket1/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from tf_utils import load_dataset, random_mini_batches\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've imported everything. Let's write out some basic routines now.\n",
    "\n",
    "First thing, create placeholders for the input and output data. We keep the shape of X (input) and Y (output) totally free. Will see if this creates some problems later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholder(nx, ny) : \n",
    "    X = tf.placeholder(dtype = tf.float32, shape = [nx, None], name = 'X')\n",
    "    Y = tf.placeholder(dtype = tf.float32, shape = [ny, None], name = 'Y')\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've got this in place. Let's make some neural networks! We want to create tf.Variables to represent matrices corresponding to each layer. Variables are the ones tf performs derivatives etc. \n",
    "\n",
    "We also take in a list of numbers corresponding to number of neurons in each layer. Return lists containing matrices and biases corresponding to each layer. So first one is of shape (layer 1, input_size)...(output size, layer n-1).\n",
    "\n",
    "**NOTE** : List should include input size as first number and output size as last number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    tf.set_random_seed(1)                   # so that your \"random\" numbers match ours\n",
    "        \n",
    "    ### START CODE HERE ### (approx. 6 lines of code)\n",
    "    W1 = tf.get_variable(\"W1\", [25, 12288], initializer= tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [25, 1], initializer= tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [12, 25], initializer= tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable(\"b2\", [12, 1], initializer= tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [6, 12], initializer= tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b3 = tf.get_variable(\"b3\", [6, 1], initializer= tf.zeros_initializer())\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_params(num_neurons) :    \n",
    "    n_layers = len(num_neurons)\n",
    "    Warr = [] \n",
    "    barr = []\n",
    "    for i in np.arange(n_layers-1) : \n",
    "        Warr.append(tf.get_variable(dtype = tf.float32, \\\n",
    "        shape = [num_neurons[i+1], num_neurons[i]], name = 'W{}'.format(i), \\\n",
    "            initializer = tf.contrib.layers.xavier_initializer(seed = 1)))\n",
    "        barr.append(tf.get_variable(dtype = tf.float32, name = 'b{}'.format(i), \\\n",
    "        shape = [num_neurons[i+1], 1], initializer = tf.zeros_initializer()))\n",
    "    params = {'W' : Warr, 'b' : barr}\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll do a forward propagation. We take as input the data vector X, parameter dictionary, and the list of layers. We choose ReLU as the activation function. The output should be just the linear transform of the penultimate layer. The cost function in tf automatically performs a softmax activation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    ### START CODE HERE ### (approx. 5 lines)              # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)                                              # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                              # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)                                              # Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                              # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3, A2), b3)                                              # Z3 = np.dot(W3, A2) + b3\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(X, params, num_neurons) :\n",
    "    Warr = params['W']\n",
    "    barr = params['b']\n",
    "    n_layers = len(num_neurons)\n",
    "    Z = tf.add(tf.matmul(Warr[0], X), barr[0]) #if there's only one layer it's logistic regression, directly return Z\n",
    "    for i in np.arange(1, n_layers-1) : \n",
    "        A = tf.nn.relu(Z)\n",
    "        Z = tf.add(tf.matmul(Warr[i], A), barr[i])\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now put together all pieces we need for the network itself. Let's now focus on the cost function. We want to use a softmax cost. So we need to ensure that the labels in our training set are represented as vectors with a 1 at the corresponding index - so-called one-hot encoding. Let's write a function to do this explicitly. We need to input the list of labels from 0 to C and C, where C is the number of classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(labels, C) : \n",
    "    one_hot_ans = tf.one_hot(labels, depth=C, axis = 0)\n",
    "    sess = tf.Session()\n",
    "    one_hot = sess.run(one_hot_ans)\n",
    "    sess.close()\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we write the cost function. We use the softmax cross entropy. One thing to note is that the output Z from forward_prop and the one_hot matrix of labels from one_hot_encoding has the shape (# classes, # examples). However, softmax_cross_entropy assumes that the shape is (# examples, # classes). So we should transpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_fn(Z, Y) : \n",
    "    logits = tf.transpose(Z)\n",
    "    labels = tf.transpose(Y)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. Now all components of our network are ready. Let's put them all together. \n",
    "\n",
    "**Note** : Again X_train should have shape (# features, # examples), Y_train should have shape (# classes, # examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, num_neurons, minibatch_size = 32, \n",
    "          num_epochs = 50, learn_rate = 0.0001, print_cost = True) : \n",
    "    #first some basic stuff\n",
    "    ops.reset_default_graph()\n",
    "    tf.set_random_seed(1)\n",
    "    seed = 3\n",
    "    costs = []\n",
    "    \n",
    "    nfeat, nexamples = X_train.shape\n",
    "    nclasses = Y_train.shape[0]\n",
    "    #create placeholders for data\n",
    "    X, Y = create_placeholder(nfeat, nclasses)\n",
    "    #create variables for NN\n",
    "    params = initialize_params(num_neurons) \n",
    "    #params = initialize_parameters()\n",
    "    #forward propagation\n",
    "    Z1 = forward_prop(X, params, num_neurons)  \n",
    "    #Z1 = forward_propagation(X, params)\n",
    "    #print(Z1.shape)\n",
    "    #calculate cost\n",
    "    cost = cost_fn(Z1, Y) \n",
    "    #Adam optimizer to minimize cost\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learn_rate).minimize(cost)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess :\n",
    "        #initialize variables\n",
    "        sess.run(init)\n",
    "        \n",
    "        #run epochs to divide data into mini-batches and use stochastic gradient descent\n",
    "        for epoch in np.arange(num_epochs) : \n",
    "          \n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(nexamples / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "            \n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run session to execute \"optimizer\" and \"cost\", the feedict containd a minibatch for (X,Y).\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict = {X : minibatch_X, Y : minibatch_Y})\n",
    "                epoch_cost += minibatch_cost / minibatch_size\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per fives)')\n",
    "        plt.title(\"Learning rate =\" + str(learn_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(params)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z1), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        \n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return parameters           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll try to run on the dataset provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is in the shape of images. We need to flatten it out and normalize to feed into our NN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flat = X_train_orig.reshape(X_train_orig.shape[0], -1).T\n",
    "X_test_flat = X_test_orig.reshape(X_test_orig.shape[0], -1).T\n",
    "X_train = X_train_flat/255\n",
    "X_test = X_test_flat/255\n",
    "Y_train = one_hot_encoding(np.squeeze(Y_train_orig), 6)\n",
    "Y_test = one_hot_encoding(np.squeeze(Y_test_orig), 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify the architecture of the neural network now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neurons = [X_train.shape[0], 25, 12, Y_train.shape[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to put things into our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.913693\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: 0.38981482\n",
      "Test Accuracy: 0.39166668\n"
     ]
    }
   ],
   "source": [
    "parameters = model(X_train, Y_train, X_test, Y_test, num_neurons, learn_rate = 0.0001, num_epochs = 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
